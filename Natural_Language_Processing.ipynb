{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Natural Language Processing.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2X7ZyVEy3ep"
      },
      "source": [
        "# Intro to Natural Language Processing in Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvJXZws4yp78"
      },
      "source": [
        "### Module 1: Regular expressions & word tokenization\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQasCE_c6umS"
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "my_string = \"Let's write RegEx!  Won't that be fun?  I sure think so.  Can you find 4 sentences?  Or perhaps, all 19 words?\""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cy4SRnjW7jgw",
        "outputId": "e90260fe-3c53-49ac-9497-45db81543c6c"
      },
      "source": [
        "sentence_endings = r\"[.?!]\"\n",
        "print(re.split(sentence_endings, my_string))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"Let's write RegEx\", \"  Won't that be fun\", '  I sure think so', '  Can you find 4 sentences', '  Or perhaps, all 19 words', '']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcn9dVuxzAyJ"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjI6wmpZ7l5J",
        "outputId": "2291005d-92a0-4f2e-f556-0fa85f718084"
      },
      "source": [
        "capitalized_words = r\"[A-Z]\\w+\"\n",
        "print(re.findall(capitalized_words, my_string))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Let', 'RegEx', 'Won', 'Can', 'Or']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYZYRX4Z8DzH",
        "outputId": "8749305b-1352-40f3-82de-0516bec71cbc"
      },
      "source": [
        "spaces = r\"\\s+\"\n",
        "print(re.split(spaces, my_string))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"Let's\", 'write', 'RegEx!', \"Won't\", 'that', 'be', 'fun?', 'I', 'sure', 'think', 'so.', 'Can', 'you', 'find', '4', 'sentences?', 'Or', 'perhaps,', 'all', '19', 'words?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyjjQvgt8FwF",
        "outputId": "8722cc29-cb14-4229-f535-a2d5089a1f4b"
      },
      "source": [
        "digits = r\"\\d+\"\n",
        "print(re.findall(digits, my_string))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['4', '19']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2F3wBIHf8H4F"
      },
      "source": [
        "from nltk.tokenize import sent_tokenize \n",
        "#tokenize a document into sentences\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "#monty python's holy grail\n",
        "scene_one = \"SCENE 1: [wind] [clop clop clop] \\nKING ARTHUR: Whoa there!  [clop clop clop] \\nSOLDIER #1: Halt!  Who goes there?\\nARTHUR: It is I, Arthur, son of Uther Pendragon, from the castle of Camelot.  King of the Britons, defeator of the Saxons, sovereign of all England!\\nSOLDIER #1: Pull the other one!\\nARTHUR: I am, ...  and this is my trusty servant Patsy.  We have ridden the length and breadth of the land in search of knights who will join me in my court at Camelot.  I must speak with your lord and master.\\nSOLDIER #1: What?  Ridden on a horse?\\nARTHUR: Yes!\\nSOLDIER #1: You're using coconuts!\\nARTHUR: What?\\nSOLDIER #1: You've got two empty halves of coconut and you're bangin' 'em together.\\nARTHUR: So?  We have ridden since the snows of winter covered this land, through the kingdom of Mercea, through--\\nSOLDIER #1: Where'd you get the coconuts?\\nARTHUR: We found them.\\nSOLDIER #1: Found them?  In Mercea?  The coconut's tropical!\\nARTHUR: What do you mean?\\nSOLDIER #1: Well, this is a temperate zone.\\nARTHUR: The swallow may fly south with the sun or the house martin or the plover may seek warmer climes in winter, yet these are not strangers to our land?\\nSOLDIER #1: Are you suggesting coconuts migrate?\\nARTHUR: Not at all.  They could be carried.\\nSOLDIER #1: What?  A swallow carrying a coconut?\\nARTHUR: It could grip it by the husk!\\nSOLDIER #1: It's not a question of where he grips it!  It's a simple question of weight ratios!  A five ounce bird could not carry a one pound coconut.\\nARTHUR: Well, it doesn't matter.  Will you go and tell your master that Arthur from the Court of Camelot is here.\\nSOLDIER #1: Listen.  In order to maintain air-speed velocity, a swallow needs to beat its wings forty-three times every second, right?\\nARTHUR: Please!\\nSOLDIER #1: Am I right?\\nARTHUR: I'm not interested!\\nSOLDIER #2: It could be carried by an African swallow!\\nSOLDIER #1: Oh, yeah, an African swallow maybe, but not a European swallow.  That's my point.\\nSOLDIER #2: Oh, yeah, I agree with that.\\nARTHUR: Will you ask your master if he wants to join my court at Camelot?!\\nSOLDIER #1: But then of course a-- African swallows are non-migratory.\\nSOLDIER #2: Oh, yeah...\\nSOLDIER #1: So they couldn't bring a coconut back anyway...  [clop clop clop] \\nSOLDIER #2: Wait a minute!  Supposing two swallows carried it together?\\nSOLDIER #1: No, they'd have to have it on a line.\\nSOLDIER #2: Well, simple!  They'd just use a strand of creeper!\\nSOLDIER #1: What, held under the dorsal guiding feathers?\\nSOLDIER #2: Well, why not?\\n\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRNVhGrn8NU8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5315ba4-bcfc-45ee-b793-b1f39f1a6b15"
      },
      "source": [
        "nltk.download('punkt')\n",
        "sentences = sent_tokenize(scene_one)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XQuDPJ1EGac"
      },
      "source": [
        "tokenized_sent = word_tokenize(sentences[3])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhgM-DJYEgFi"
      },
      "source": [
        "unique_tokens = set(word_tokenize(scene_one))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPdR5QRFEjGn",
        "outputId": "2b00d623-d75f-4cf1-d9ca-e091262d1495"
      },
      "source": [
        "print(unique_tokens)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'join', 'The', 'They', 'Uther', 'ridden', \"'em\", 'strangers', 'they', 'my', 'by', \"'\", 'Mercea', 'minute', 'Pendragon', 'servant', 'grips', 'using', 'needs', '!', 'Patsy', 'wants', 'here', 'from', 'all', 'these', 'Court', 'may', 'them', 'and', 'bring', 'grip', 'feathers', 'Are', 'King', 'be', 'zone', 'where', 'length', 'just', 'coconuts', 'but', 'together', '.', 'kingdom', 'other', 'guiding', 'will', 'Yes', 'No', 'Wait', 'our', '1', 'on', 'your', 'warmer', 'sovereign', 'times', 'simple', 'five', 'Will', 'get', \"'d\", 'Found', 'But', 'am', 'speak', 'yeah', 'ounce', 'strand', 'is', '...', 'does', 'at', 'migrate', 'ratios', 'if', 'non-migratory', 'or', 'held', '--', 'interested', '?', '2', '[', \"n't\", \"'m\", 'weight', \"'re\", 'Camelot', '#', 'search', 'horse', 'velocity', 'coconut', 'Am', 'every', 'Supposing', 'husk', 'A', 'ask', 'order', 'to', ',', 'bangin', 'forty-three', 'court', 'master', 'yet', 'You', 'I', 'halves', 'empty', 'suggesting', ':', 'since', 'climes', 'south', 'Britons', 'must', 'that', 'covered', 'What', 'course', 'Not', 'bird', 'air-speed', 'land', 'plover', 'In', 'of', 'agree', ']', 'breadth', 'house', 'It', 'tropical', 'not', 'Please', 'through', 'carried', 'Arthur', 'lord', 'a', \"'s\", 'its', 'Who', 'this', 'So', 'SOLDIER', 'tell', 'knights', 'right', 'African', 'under', 'Halt', 'got', 'point', 'wind', 'there', 'he', 'maybe', 'creeper', 'Listen', 'back', 'could', 'found', 'do', 'use', 'Where', 'Ridden', 'then', 'trusty', 'Well', 'me', 'That', 'carrying', 'pound', 'Saxons', 'wings', 'swallows', 'swallow', 'fly', 'SCENE', 'England', 'sun', 'go', 'line', 'with', 'second', 'Pull', 'have', \"'ve\", 'who', 'one', 'anyway', 'are', 'goes', 'carry', 'snows', 'We', 'in', 'two', 'winter', 'martin', 'Whoa', 'clop', 'castle', 'an', 'question', 'maintain', 'mean', 'beat', 'matter', 'temperate', 'why', 'the', 'it', 'KING', 'Oh', 'ARTHUR', 'dorsal', 'defeator', 'you', 'seek', 'son', 'European'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHoq_fQDEpm5",
        "outputId": "10a1d7fc-7c3c-4877-d908-6763ed41f38e"
      },
      "source": [
        "match = re.search(r\"coconuts\", scene_one)\n",
        "print(match.start(), match.end())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "580 588\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vUzUg6jE77D",
        "outputId": "c60249a9-22a1-4553-ef88-bd2d06b9af7d"
      },
      "source": [
        "pattern1 = r\"\\[.*]\"\n",
        "print(re.search(pattern1, scene_one))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<re.Match object; span=(9, 32), match='[wind] [clop clop clop]'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSSTT9HYF4-f",
        "outputId": "5fad3c8c-b8ba-49fa-b15a-3779fa83b32b"
      },
      "source": [
        "pattern2 = r\"[\\w\\s]+:\"\n",
        "print(re.match(pattern2, sentences[3]))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<re.Match object; span=(0, 7), match='ARTHUR:'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNZErKbcGhDW",
        "outputId": "bbcbf09a-0b60-4eea-b61a-b11a8a71d2f1"
      },
      "source": [
        "from nltk.tokenize import regexp_tokenize\n",
        "my_string = \"SOLDIER #1: Found them? In Mercea? The coconut's tropical!\"\n",
        "pattern3 = r\"(\\w+|#\\d|\\?|!)\"\n",
        "regexp_tokenize(my_string, pattern3)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['SOLDIER',\n",
              " '#1',\n",
              " 'Found',\n",
              " 'them',\n",
              " '?',\n",
              " 'In',\n",
              " 'Mercea',\n",
              " '?',\n",
              " 'The',\n",
              " 'coconut',\n",
              " 's',\n",
              " 'tropical',\n",
              " '!']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaFAhST6JbQS"
      },
      "source": [
        "from nltk.tokenize import TweetTokenizer"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqCtgBlBJ8p_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65844623-bb62-47f6-e5ba-16ac231ec6d9"
      },
      "source": [
        "tweets = ['This is the best #nlp exercise ive found online! #python',\n",
        " '#NLP is super fun! <3 #learning',\n",
        " 'Thanks @datacamp :) #nlp #python']\n",
        "pattern2 = r\"([@|#]\\w+)\"\n",
        "mentions_hashtags = regexp_tokenize(tweets[-1], pattern2)\n",
        "print(mentions_hashtags)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['@datacamp', '#nlp', '#python']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5MCT1xVvylp",
        "outputId": "24a7d5a5-3fc6-45e7-ec05-b4a79b8bd307"
      },
      "source": [
        "tknzr = TweetTokenizer()\n",
        "all_tokens = [tknzr.tokenize(t) for t in tweets]\n",
        "print(all_tokens)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['This', 'is', 'the', 'best', '#nlp', 'exercise', 'ive', 'found', 'online', '!', '#python'], ['#NLP', 'is', 'super', 'fun', '!', '<3', '#learning'], ['Thanks', '@datacamp', ':)', '#nlp', '#python']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VgM8Ih_wBBO",
        "outputId": "e56f55a4-5729-49cf-a30f-ec618982c783"
      },
      "source": [
        "german_text = \"Wann gehen wir Pizza essen? 🍕 Und fährst du mit Über? 🚕\"\n",
        "all_words = word_tokenize(german_text)\n",
        "print(all_words)\n",
        "\n",
        "# Tokenize and print only capital words\n",
        "capital_words = r\"[A-Z|Ü]\\w+\"\n",
        "print(regexp_tokenize(german_text, capital_words))\n",
        "\n",
        "# Tokenize and print only emoji\n",
        "emoji = \"['\\U0001F300-\\U0001F5FF'|'\\U0001F600-\\U0001F64F'|'\\U0001F680-\\U0001F6FF'|'\\u2600-\\u26FF\\u2700-\\u27BF']\"\n",
        "print(regexp_tokenize(german_text, emoji))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Wann', 'gehen', 'wir', 'Pizza', 'essen', '?', '🍕', 'Und', 'fährst', 'du', 'mit', 'Über', '?', '🚕']\n",
            "['Wann', 'Pizza', 'Und', 'Über']\n",
            "['🍕', '🚕']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcTwUhRxx3Lg"
      },
      "source": [
        "import requests as rq\n",
        "result = rq.get('https://assets.datacamp.com/production/repositories/932/datasets/4921d0bf6a73fd645f49f528faf74a871bb3a0e9/grail.txt')\n",
        "text = result.text"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "4lS93_tH3lVM",
        "outputId": "ff6e1785-cfda-4b53-c0e0-c6fd1d559d98"
      },
      "source": [
        "#pyplot introduction\n",
        "from matplotlib import pyplot as plt\n",
        "plt.hist([1,5,5,7,7,7,9])\n",
        "plt.show()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAPF0lEQVR4nO3dfayedX3H8fdHWh9AJws9m10fPCQQMzUT8KTi3AyRsYAQWDaWQDJ8iEs3gxtsJgv6B0b/0mTRRTGShjLBIT4Amk7qA4lk6h9WTmt5aKtLx1DadaOCFjudWPfdH/dVcnY8p/d9eu7T6/Tn+5Xc6fXwO/f14eT00+v87uu6SFUhSTr5PafvAJKk8bDQJakRFrokNcJCl6RGWOiS1IgVfR141apVNTk52dfhJemktH379h9U1cRc+3or9MnJSaanp/s6vCSdlJJ8b759TrlIUiMsdElqhIUuSY2w0CWpERa6JDXCQpekRgwt9CTPT/KtJA8m2ZXkvXOMeV6STyfZm2RbksmlCCtJmt8oZ+g/A95QVa8CzgEuTnL+rDFvA35YVWcBHwI+MN6YkqRhhhZ6DRzuVld2r9kPUb8CuK1bvgu4MEnGllKSNNRId4omOQXYDpwFfLSqts0asgZ4HKCqjiQ5BJwB/GDW+2wENgKsX79+cckljc3kDff2duzH3n9pb8duzUgfilbVL6rqHGAtsCHJK4/nYFW1qaqmqmpqYmLORxFIko7Tgq5yqaofAfcDF8/atR9YB5BkBfBi4MlxBJQkjWaUq1wmkpzeLb8AuAj4zqxhW4A3d8tXAl8t/2elknRCjTKHvhq4rZtHfw7wmar6QpL3AdNVtQXYDHwiyV7gKeCqJUssSZrT0EKvqoeAc+fYfuOM5f8B/nS80SRJC+GdopLUCAtdkhphoUtSIyx0SWqEhS5JjbDQJakRFrokNcJCl6RGWOiS1AgLXZIaYaFLUiMsdElqhIUuSY2w0CWpERa6JDXCQpekRljoktQIC12SGmGhS1IjLHRJaoSFLkmNsNAlqREWuiQ1wkKXpEZY6JLUiKGFnmRdkvuT7E6yK8l1c4y5IMmhJDu7141LE1eSNJ8VI4w5AryzqnYkeRGwPcl9VbV71rivV9Vl448oSRrF0DP0qjpQVTu65R8De4A1Sx1MkrQwC5pDTzIJnAtsm2P3a5M8mOSLSV4xz9dvTDKdZPrgwYMLDitJmt/IhZ7khcDdwPVV9fSs3TuAl1bVq4CPAJ+f6z2qalNVTVXV1MTExPFmliTNYaRCT7KSQZnfUVX3zN5fVU9X1eFueSuwMsmqsSaVJB3TKFe5BNgM7KmqD84z5iXdOJJs6N73yXEGlSQd2yhXubwOuAZ4OMnObtu7gfUAVXUzcCXw9iRHgJ8CV1VVLUFeSdI8hhZ6VX0DyJAxNwE3jSuUJGnhvFNUkhphoUtSIyx0SWqEhS5JjbDQJakRFrokNcJCl6RGWOiS1AgLXZIaYaFLUiMsdElqhIUuSY2w0CWpERa6JDXCQpekRljoktQIC12SGmGhS1IjLHRJaoSFLkmNsNAlqREWuiQ1wkKXpEZY6JLUCAtdkhphoUtSI4YWepJ1Se5PsjvJriTXzTEmST6cZG+Sh5KctzRxJUnzWTHCmCPAO6tqR5IXAduT3FdVu2eMuQQ4u3u9BvhY96ck6QQZeoZeVQeqake3/GNgD7Bm1rArgNtr4JvA6UlWjz2tJGleo5yhPyvJJHAusG3WrjXA4zPW93XbDsz6+o3ARoD169cvLKl0Ak3ecG8vx33s/Zf2cly1YeQPRZO8ELgbuL6qnj6eg1XVpqqaqqqpiYmJ43kLSdI8Rir0JCsZlPkdVXXPHEP2A+tmrK/ttkmSTpBRrnIJsBnYU1UfnGfYFuBN3dUu5wOHqurAPGMlSUtglDn01wHXAA8n2dltezewHqCqbga2Am8E9gI/Ad46/qiSpGMZWuhV9Q0gQ8YUcO24QkmSFs47RSWpERa6JDXCQpekRljoktQIC12SGmGhS1IjLHRJaoSFLkmNsNAlqREWuiQ1wkKXpEZY6JLUCAtdkhphoUtSIyx0SWqEhS5JjbDQJakRFrokNcJCl6RGWOiS1AgLXZIaYaFLUiMsdElqhIUuSY2w0CWpEUMLPcmtSZ5I8sg8+y9IcijJzu514/hjSpKGWTHCmI8DNwG3H2PM16vqsrEkkiQdl6Fn6FX1NeCpE5BFkrQI45pDf22SB5N8Mckr5huUZGOS6STTBw8eHNOhJUkwnkLfAby0ql4FfAT4/HwDq2pTVU1V1dTExMQYDi1JOmrRhV5VT1fV4W55K7AyyapFJ5MkLciiCz3JS5KkW97QveeTi31fSdLCDL3KJcmdwAXAqiT7gPcAKwGq6mbgSuDtSY4APwWuqqpassSSpDkNLfSqunrI/psYXNYoSeqRd4pKUiMsdElqhIUuSY2w0CWpERa6JDXCQpekRljoktQIC12SGmGhS1IjLHRJaoSFLkmNsNAlqREWuiQ1wkKXpEZY6JLUCAtdkhphoUtSIyx0SWqEhS5JjbDQJakRFrokNcJCl6RGWOiS1AgLXZIaYaFLUiMsdElqxNBCT3JrkieSPDLP/iT5cJK9SR5Kct74Y0qShhnlDP3jwMXH2H8JcHb32gh8bPGxJEkLNbTQq+prwFPHGHIFcHsNfBM4PcnqcQWUJI1mxRjeYw3w+Iz1fd22A7MHJtnI4Cye9evXH/cBJ2+497i/drEee/+lvR1b0vi02CMn9EPRqtpUVVNVNTUxMXEiDy1JzRtHoe8H1s1YX9ttkySdQOMo9C3Am7qrXc4HDlXVL023SJKW1tA59CR3AhcAq5LsA94DrASoqpuBrcAbgb3AT4C3LlVYSdL8hhZ6VV09ZH8B144tkSTpuHinqCQ1wkKXpEZY6JLUCAtdkhphoUtSIyx0SWqEhS5JjbDQJakRFrokNcJCl6RGWOiS1AgLXZIaYaFLUiMsdElqhIUuSY2w0CWpERa6JDXCQpekRljoktQIC12SGmGhS1IjLHRJaoSFLkmNsNAlqREWuiQ1YqRCT3Jxku8m2Zvkhjn2vyXJwSQ7u9efjz+qJOlYVgwbkOQU4KPARcA+4IEkW6pq96yhn66qdyxBRknSCEY5Q98A7K2qR6vqGeBTwBVLG0uStFCjFPoa4PEZ6/u6bbP9SZKHktyVZN1cb5RkY5LpJNMHDx48jriSpPmM60PRfwYmq+p3gPuA2+YaVFWbqmqqqqYmJibGdGhJEoxW6PuBmWfca7ttz6qqJ6vqZ93qLcCrxxNPkjSqUQr9AeDsJGcmeS5wFbBl5oAkq2esXg7sGV9ESdIohl7lUlVHkrwD+DJwCnBrVe1K8j5guqq2AH+d5HLgCPAU8JYlzCxJmsPQQgeoqq3A1lnbbpyx/C7gXeONJklaCO8UlaRGWOiS1AgLXZIaYaFLUiMsdElqhIUuSY2w0CWpERa6JDXCQpekRljoktQIC12SGmGhS1IjLHRJaoSFLkmNsNAlqREWuiQ1wkKXpEZY6JLUCAtdkhphoUtSIyx0SWqEhS5JjbDQJakRFrokNcJCl6RGWOiS1IiRCj3JxUm+m2Rvkhvm2P+8JJ/u9m9LMjnuoJKkYxta6ElOAT4KXAK8HLg6yctnDXsb8MOqOgv4EPCBcQeVJB3bKGfoG4C9VfVoVT0DfAq4YtaYK4DbuuW7gAuTZHwxJUnDrBhhzBrg8Rnr+4DXzDemqo4kOQScAfxg5qAkG4GN3erhJN89ntDAqtnvfaLk2L979JZrBMs1m7lmGPLzBQ1+v0b4b16MZfn9ygcWleul8+0YpdDHpqo2AZsW+z5JpqtqagyRxmq55oLlm81cC2OuhflVyzXKlMt+YN2M9bXdtjnHJFkBvBh4chwBJUmjGaXQHwDOTnJmkucCVwFbZo3ZAry5W74S+GpV1fhiSpKGGTrl0s2JvwP4MnAKcGtV7UryPmC6qrYAm4FPJNkLPMWg9JfSoqdtlshyzQXLN5u5FsZcC/MrlSueSEtSG7xTVJIaYaFLUiNOqkJPcmuSJ5I80neWmZKsS3J/kt1JdiW5ru9MAEmen+RbSR7scr2370wzJTklybeTfKHvLEcleSzJw0l2JpnuO89RSU5PcleS7yTZk+S1yyDTy7rv09HX00mu7zsXQJK/6X7mH0lyZ5Ln950JIMl1XaZdS/G9Oqnm0JO8HjgM3F5Vr+w7z1FJVgOrq2pHkhcB24E/qqrdPecKcFpVHU6yEvgGcF1VfbPPXEcl+VtgCvi1qrqs7zwwKHRgqqqW1c0oSW4Dvl5Vt3RXm51aVT/qO9dR3SNC9gOvqarv9ZxlDYOf9ZdX1U+TfAbYWlUf7znXKxncab8BeAb4EvCXVbV3XMc4qc7Qq+prDK6iWVaq6kBV7eiWfwzsYXD3bK9q4HC3urJ7LYt/wZOsBS4Fbuk7y3KX5MXA6xlcTUZVPbOcyrxzIfBvfZf5DCuAF3T3xZwK/EfPeQB+G9hWVT+pqiPAvwB/PM4DnFSFfjLonjR5LrCt3yQD3bTGTuAJ4L6qWha5gH8A/g74376DzFLAV5Js7x5VsRycCRwE/rGborolyWl9h5rlKuDOvkMAVNV+4O+B7wMHgENV9ZV+UwHwCPD7Sc5IcirwRv7/TZuLZqGPUZIXAncD11fV033nAaiqX1TVOQzu8N3Q/drXqySXAU9U1fa+s8zh96rqPAZPF722m+br2wrgPOBjVXUu8N/ALz3Gui/dFNDlwGf7zgKQ5NcZPDDwTOC3gNOS/Fm/qaCq9jB4Eu1XGEy37AR+Mc5jWOhj0s1R3w3cUVX39J1ntu5X9PuBi/vOArwOuLybr/4U8IYk/9RvpIHu7I6qegL4HIP5zr7tA/bN+O3qLgYFv1xcAuyoqv/qO0jnD4B/r6qDVfVz4B7gd3vOBEBVba6qV1fV64EfAv86zve30Meg+/BxM7Cnqj7Yd56jkkwkOb1bfgFwEfCdflNBVb2rqtZW1SSDX9W/WlW9n0ElOa37UJtuSuMPGfya3Kuq+k/g8SQv6zZdCPT6gfssV7NMpls63wfOT3Jq93fzQgafa/UuyW90f65nMH/+yXG+/wl92uJiJbkTuABYlWQf8J6q2txvKmBwxnkN8HA3Xw3w7qra2mMmgNXAbd0VCM8BPlNVy+YSwWXoN4HPdY/yXwF8sqq+1G+kZ/0VcEc3vfEo8Nae8wDP/sN3EfAXfWc5qqq2JbkL2AEcAb7N8nkEwN1JzgB+Dlw77g+3T6rLFiVJ83PKRZIaYaFLUiMsdElqhIUuSY2w0CWpERa6JDXCQpekRvwfPmv9Et//pIMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "Lg0EpWy8yJ9D",
        "outputId": "b885201f-32ce-4163-b82c-4a5fa9a269a2"
      },
      "source": [
        "#print(text)\n",
        "lines = text.split('\\n')\n",
        "\n",
        "# Replace all script lines for speaker\n",
        "pattern = \"[A-Z]{2,}(\\s)?(#\\d)?([A-Z]{2,})?:\"\n",
        "lines = [re.sub(pattern, '', l) for l in lines]\n",
        "\n",
        "# Tokenize each line: tokenized_lines\n",
        "tokenized_lines = [regexp_tokenize(s, \"\\w+\") for s in lines]\n",
        "\n",
        "# Make a frequency list of lengths: line_num_words\n",
        "line_num_words = [len(t_line) for t_line in tokenized_lines]\n",
        "\n",
        "# Plot a histogram of the line lengths\n",
        "plt.hist(line_num_words)\n",
        "\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "2WYy07mo3udP",
        "outputId": "09ac5687-24cb-498b-8164-f9501d00dfb8"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "words = word_tokenize(\"This is a pretty cool tool!\")\n",
        "word_length = [len(w) for w in words]\n",
        "plt.hist(word_length)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([2., 0., 1., 0., 0., 0., 3., 0., 0., 1.]),\n",
              " array([1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. , 5.5, 6. ]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFru-TJXyc9Q"
      },
      "source": [
        "### Module 2: Topic Identification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OP0sEfPRCcMV"
      },
      "source": [
        "text = \"The cat is in the box. The cat likes the box. The box is over the cat.\""
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUTKnUL84u4k"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "counter = Counter(word_tokenize(text))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBvDXacr-o5E",
        "outputId": "2de16093-83d2-45d9-a7d9-62db132fd9ea"
      },
      "source": [
        "counter.most_common(2)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('The', 3), ('cat', 3)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6IRpaoZiv_k"
      },
      "source": [
        "request = rq.get('https://s3.amazonaws.com/assets.datacamp.com/production/course_3910/datasets/wiki_text_debugging.txt')\n",
        "article = result.text"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AzLHwIljMS_",
        "outputId": "e5f28221-92b4-40ba-f280-ce2a689985bd"
      },
      "source": [
        "tokens = word_tokenize(article)\n",
        "\n",
        "# Convert the tokens into lowercase: lower_tokens\n",
        "lower_tokens = [t.lower() for t in tokens]\n",
        "\n",
        "# Create a Counter with the lowercase tokens: bow_simple\n",
        "bow_simple = Counter(lower_tokens)\n",
        "\n",
        "# Print the 10 most common tokens\n",
        "print(bow_simple.most_common(10))\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(':', 1197), ('.', 838), ('!', 830), (',', 746), ('the', 333), ('[', 320), (']', 320), ('you', 263), ('arthur', 261), ('i', 258)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G36cpgQQ_PyQ",
        "outputId": "941b63d5-ff7a-4fc4-9ef2-a1f6ca814e2a"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "tokens = [w for w in word_tokenize(text.lower()) if w.isalpha()]\n",
        "nltk.download('stopwords')\n",
        "no_stops = [t for t in tokens if t not in stopwords.words('english')]\n",
        "Counter(no_stops).most_common(2)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('cat', 3), ('box', 3)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALhNaujAjqGt",
        "outputId": "edcf8401-8d74-482c-fe8c-ee277582cbff"
      },
      "source": [
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Lemmatize all tokens into a new list: lemmatized\n",
        "lemmatized = [wordnet_lemmatizer.lemmatize(t) for t in no_stops]\n",
        "\n",
        "# Create the bag-of-words: bow\n",
        "bow = Counter(lemmatized)\n",
        "\n",
        "# Print the 10 most common tokens\n",
        "print(bow.most_common(10))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[('cat', 3), ('box', 3), ('like', 1)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSOZ9paDBaIc",
        "outputId": "6a85952a-f39c-428b-cbee-56f8d53fcdac"
      },
      "source": [
        "print(tokens)\n",
        "print(no_stops)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['the', 'cat', 'is', 'in', 'the', 'box', 'the', 'cat', 'likes', 'the', 'box', 'the', 'box', 'is', 'over', 'the', 'cat']\n",
            "['cat', 'box', 'cat', 'likes', 'box', 'box', 'cat']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zg_guboZCTtw"
      },
      "source": [
        "from gensim.corpora.dictionary import Dictionary\n",
        "my_documents = ['The movie was about spaceship and aliens.', \n",
        "                'I really liked the movie.', \n",
        "                'Awesome action scenes but boring characters', \n",
        "                'The movie was awful! I hate alien films',\n",
        "                'More space films, please!']\n",
        "            "
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGVwtKe9OoyR",
        "outputId": "88a6fa07-6c9e-4231-96f2-75b5b5415993"
      },
      "source": [
        "tokenized_docs = [word_tokenize(doc.lower()) for doc in my_documents]\n",
        "\n",
        "dic = Dictionary(tokenized_docs)\n",
        "#create a mapping with an id for each token\n",
        "dic.token2id"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'!': 17,\n",
              " ',': 22,\n",
              " '.': 0,\n",
              " 'about': 1,\n",
              " 'action': 11,\n",
              " 'alien': 18,\n",
              " 'aliens': 2,\n",
              " 'and': 3,\n",
              " 'awesome': 12,\n",
              " 'awful': 19,\n",
              " 'boring': 13,\n",
              " 'but': 14,\n",
              " 'characters': 15,\n",
              " 'films': 20,\n",
              " 'hate': 21,\n",
              " 'i': 8,\n",
              " 'liked': 9,\n",
              " 'more': 23,\n",
              " 'movie': 4,\n",
              " 'please': 24,\n",
              " 'really': 10,\n",
              " 'scenes': 16,\n",
              " 'space': 25,\n",
              " 'spaceship': 5,\n",
              " 'the': 6,\n",
              " 'was': 7}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhijmE5UPObr",
        "outputId": "31572a50-c405-4bb7-a73d-266d4d39a65f"
      },
      "source": [
        "corpus = [dic.doc2bow(doc) for doc in tokenized_docs]\n",
        "corpus"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)],\n",
              " [(0, 1), (4, 1), (6, 1), (8, 1), (9, 1), (10, 1)],\n",
              " [(11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1)],\n",
              " [(4, 1), (6, 1), (7, 1), (8, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1)],\n",
              " [(17, 1), (20, 1), (22, 1), (23, 1), (24, 1), (25, 1)]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjyqMQJqP-vC"
      },
      "source": [
        "Unlike our previous counter based bagOfWords model, this gensim model can be easily saved, updated and reused owing to the extra tools that Gensim has."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhsQVfHxlVaB"
      },
      "source": [
        "### Module 3: Named Entity Recognition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62krfNp_PqK8",
        "outputId": "b9dbb781-732a-4a0a-c55e-a57b6c34cac0"
      },
      "source": [
        "#create a Dictionary: mapping from token_id to words and corpus: set of text used to perform natural language processing task\n",
        "\n",
        "from gensim.corpora.dictionary import Dictionary \n",
        "articles = [['jahnvi', 'annika', 'jahnvi'], ['sophomore', 'fifth', 'class', 'don', 'chips', 'fifth','don']]\n",
        "dictionary = Dictionary(articles)\n",
        "dictionary"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<gensim.corpora.dictionary.Dictionary at 0x7f231abb2b10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THT54QLZFucE",
        "outputId": "f9c1a0af-7b57-45b2-8fe4-20e35b003614"
      },
      "source": [
        "soph_id = dictionary.token2id.get('sophomore')\n",
        "soph_id"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWgI2gJPGbq4",
        "outputId": "754ffb81-987f-4b2c-9a94-72f88a7ee431"
      },
      "source": [
        "corpus = [dictionary.doc2bow(article) for article in articles]\n",
        "print(corpus)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[(0, 1), (1, 2)], [(2, 1), (3, 1), (4, 2), (5, 2), (6, 1)]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKaOaJzuGs-L",
        "outputId": "62f43cfe-9ab5-4a73-f3e7-3e8e6c1fea4b"
      },
      "source": [
        "print(dictionary)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dictionary(7 unique tokens: ['annika', 'jahnvi', 'chips', 'class', 'don']...)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZUWEHJ1Gxpv",
        "outputId": "24fca153-2a87-4f1b-fdbe-32a7a179240a"
      },
      "source": [
        "print(corpus[1][:3])\n",
        "#print the first 3 word ids with their frequency count from the first document"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(2, 1), (3, 1), (4, 2)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qwxd7jrFHHmA",
        "outputId": "9ccd7676-65f0-47bb-954f-cc3ea4ab4771"
      },
      "source": [
        "dictionary[4]"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'don'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFHHRYCTHZQk",
        "outputId": "2a3bebb6-a403-46e8-99a5-4f829adb3121"
      },
      "source": [
        "#putting the forst document in doc so that we can analyse frequency and all\n",
        "doc = corpus[1]   #first document\n",
        "bow_doc = sorted(doc, key=lambda w:w[1], reverse=True)\n",
        "#sort the tokens in first document by their frequency\n",
        "\n",
        "for word_id, word_count in bow_doc[:5]:\n",
        "  print(dictionary.get(word_id), word_count)\n",
        "\n",
        "\n",
        "#now what we want to do is, take each word from the corpus and find its frequency in the document. \n",
        "#So to have a default frequency of 0 for words which don't occur in our document, we use defaultdict\n",
        "from collections import defaultdict\n",
        "import itertools\n",
        "\n",
        "total_word_count = defaultdict(int)\n",
        "for word_id, word_count in itertools.chain.from_iterable(corpus):\n",
        "  total_word_count[word_id] += word_count\n",
        "\n",
        "#itertools.chain.from_iterable(corpus) enables to iterate over a list of lists as if it was a single list"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "don 2\n",
            "fifth 2\n",
            "chips 1\n",
            "class 1\n",
            "sophomore 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3fBFV-VHvUs",
        "outputId": "74d7c8a5-e006-417e-8057-7bb3c30bcdee"
      },
      "source": [
        "#words across all documents with frequency in decreasing order\n",
        "sorted_word_count = sorted(total_word_count.items(), key=lambda w: w[1], reverse=True) \n",
        "sorted_word_count"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 2), (4, 2), (5, 2), (0, 1), (2, 1), (3, 1), (6, 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYgfOf_RKz6Y",
        "outputId": "8717cc00-452b-4c69-dc83-041549c584a3"
      },
      "source": [
        "#find the 5 most common words across all documents\n",
        "for word_id, word_count in sorted_word_count[:5]:\n",
        "    print(dictionary.get(word_id), word_count)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "jahnvi 2\n",
            "don 2\n",
            "fifth 2\n",
            "annika 1\n",
            "chips 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxRoOg5gzs2g"
      },
      "source": [
        "### Module 3: Named Entity Recognition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ALAaB3ELoRd",
        "outputId": "c400c22e-001f-4c2d-d72e-d4305c76f5d3"
      },
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "sent = '''In New York, I like to ride the metro to visit MOMA and some restaurants rated well by Ruth Reichel'''\n",
        "tokenized_sent = nltk.word_tokenize(sent)\n",
        "tagged_sent = nltk.pos_tag(tokenized_sent)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoiU288maShR",
        "outputId": "994062b9-ad1d-4c5d-ba29-377c7d756c52"
      },
      "source": [
        "tagged_sent[:3]"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('In', 'IN'), ('New', 'NNP'), ('York', 'NNP')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0HKSEvyaWIM",
        "outputId": "bf330713-17f8-4dc7-eea2-3d68547a4790"
      },
      "source": [
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "print(nltk.ne_chunk(tagged_sent))\n",
        "\n",
        "#it'll return the sentence as a tree\n",
        "#it tags without using any knowledge base like wikipedia but uses trained statistical and grammatical parsers"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "(S\n",
            "  In/IN\n",
            "  (GPE New/NNP York/NNP)\n",
            "  ,/,\n",
            "  I/PRP\n",
            "  like/VBP\n",
            "  to/TO\n",
            "  ride/VB\n",
            "  the/DT\n",
            "  metro/NN\n",
            "  to/TO\n",
            "  visit/VB\n",
            "  (ORGANIZATION MOMA/NNP)\n",
            "  and/CC\n",
            "  some/DT\n",
            "  restaurants/NNS\n",
            "  rated/VBN\n",
            "  well/RB\n",
            "  by/IN\n",
            "  (PERSON Ruth/NNP Reichel/NNP))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzbWqRZ5oB5E"
      },
      "source": [
        "article = 'The taxi-hailing company Uber brings into very sharp focus the question of whether corporations can be said to have a moral character. If any human being were to behave with the single-minded and ruthless greed of the company, we would consider them sociopathic. Uber wanted to know as much as possible about the people who use its service, and those who don’t. It has an arrangement with unroll.me, a company which offered a free service for unsubscribing from junk mail, to buy the contacts unroll.me customers had had with rival taxi companies. Even if their email was notionally anonymised, this use of it was not something the users had bargained for. Beyond that, it keeps track of the phones that have been used to summon its services even after the original owner has sold them, attempting this with Apple’s phones even thought it is forbidden by the company. Uber has also tweaked its software so that regulatory agencies that the company regarded as hostile would, when they tried to hire a driver, be given false reports about the location of its cars. Uber management booked and then cancelled rides with a rival taxi-hailing company which took their vehicles out of circulation. Uber deny this was the intention. The punishment for this behaviour was negligible. Uber promised not to use this “greyball” software against law enforcement – one wonders what would happen to someone carrying a knife who promised never to stab a policeman with it. Travis Kalanick of Uber got a personal dressing down from Tim Cook, who runs Apple, but the company did not prohibit the use of the app. Too much money was at stake for that. Millions of people around the world value the cheapness and convenience of Uber’s rides too much to care about the lack of drivers’ rights or pay. Many of the users themselves are not much richer than the drivers. The “sharing economy” encourages the insecure and exploited to exploit others equally insecure to the profit of a tiny clique of billionaires. Silicon Valley’s culture seems hostile to humane and democratic values. The outgoing CEO of Yahoo, Marissa Mayer, who is widely judged to have been a failure, is likely to get a $186m payout. This may not be a cause for panic, any more than the previous hero worship should have been a cause for euphoria. Yet there’s an urgent political task to tame these companies, to ensure they are punished when they break the law, that they pay their taxes fairly and that they behave responsibly.'"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNHScOW5oNmm",
        "outputId": "dd3747f4-b1ff-4b49-97e7-b414d3302f86"
      },
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "# Tokenize the article into sentences: sentences\n",
        "sentences = sent_tokenize(article)\n",
        "\n",
        "# Tokenize each sentence into words: token_sentences\n",
        "token_sentences = [word_tokenize(sent) for sent in sentences]\n",
        "\n",
        "# Tag each tokenized sentence into parts of speech: pos_sentences\n",
        "pos_sentences = [nltk.pos_tag(sent) for sent in token_sentences] \n",
        "\n",
        "# Create the named entity chunks: chunked_sentences\n",
        "chunked_sentences = nltk.ne_chunk_sents(pos_sentences, binary=True)\n",
        "\n",
        "# Test for stems of the tree with 'NE' tags\n",
        "for sent in chunked_sentences:\n",
        "    for chunk in sent:\n",
        "        if hasattr(chunk, \"label\") and chunk.label() == \"NE\":\n",
        "            print(chunk)\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "(NE Uber/NNP)\n",
            "(NE Beyond/NN)\n",
            "(NE Apple/NNP)\n",
            "(NE Uber/NNP)\n",
            "(NE Uber/NNP)\n",
            "(NE Travis/NNP Kalanick/NNP)\n",
            "(NE Tim/NNP Cook/NNP)\n",
            "(NE Apple/NNP)\n",
            "(NE Silicon/NNP Valley/NNP)\n",
            "(NE CEO/NNP)\n",
            "(NE Yahoo/NNP)\n",
            "(NE Marissa/NNP Mayer/NNP)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8lgw8viay4S"
      },
      "source": [
        "article = 'The taxi-hailing company Uber brings into very sharp focus the question of whether corporations can be said to have a moral character. If any human being were to behave with the single-minded and ruthless greed of the company, we would consider them sociopathic. Uber wanted to know as much as possible about the people who use its service, and those who don’t. It has an arrangement with unroll.me, a company which offered a free service for unsubscribing from junk mail, to buy the contacts unroll.me customers had had with rival taxi companies. Even if their email was notionally anonymised, this use of it was not something the users had bargained for. Beyond that, it keeps track of the phones that have been used to summon its services even after the original owner has sold them, attempting this with Apple’s phones even thought it is forbidden by the company.\\r\\n\\r\\n\\r\\nUber has also tweaked its software so that regulatory agencies that the company regarded as hostile would, when they tried to hire a driver, be given false reports about the location of its cars. Uber management booked and then cancelled rides with a rival taxi-hailing company which took their vehicles out of circulation. Uber deny this was the intention. The punishment for this behaviour was negligible. Uber promised not to use this “greyball” software against law enforcement – one wonders what would happen to someone carrying a knife who promised never to stab a policeman with it. Travis Kalanick of Uber got a personal dressing down from Tim Cook, who runs Apple, but the company did not prohibit the use of the app. Too much money was at stake for that.\\r\\n\\r\\n\\r\\nMillions of people around the world value the cheapness and convenience of Uber’s rides too much to care about the lack of drivers’ rights or pay. Many of the users themselves are not much richer than the drivers. The “sharing economy” encourages the insecure and exploited to exploit others equally insecure to the profit of a tiny clique of billionaires. Silicon Valley’s culture seems hostile to humane and democratic values. The outgoing CEO of Yahoo, Marissa Mayer, who is widely judged to have been a failure, is likely to get a $186m payout. This may not be a cause for panic, any more than the previous hero worship should have been a cause for euphoria. Yet there’s an urgent political task to tame these companies, to ensure they are punished when they break the law, that they pay their taxes fairly and that they behave responsibly.'\n"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkoPTceUdGzK",
        "outputId": "0ccb4d25-bf8c-476a-d78d-a28c78b1b5ad"
      },
      "source": [
        "sentences = sent_tokenize(article)\n",
        "#tokenize into sentences \n",
        "print(sentences)\n",
        "\n",
        "token_sentences = [word_tokenize(sent) for sent in sentences]\n",
        "#tokenize each sentence into words\n",
        "print(token_sentences)\n",
        "\n",
        "pos_sentences = [nltk.pos_tag(sent) for sent in token_sentences] \n",
        "#label each word in each sentence\n",
        "print(pos_sentences)\n",
        "\n",
        "chunked_sentences = nltk.ne_chunk_sents(pos_sentences, binary=True)\n",
        "#create a tree\n",
        "for sent in chunked_sentences:\n",
        "    for chunk in sent:\n",
        "        if hasattr(chunk, \"label\") and chunk.label() == \"NE\":\n",
        "            print(chunk)\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['The taxi-hailing company Uber brings into very sharp focus the question of whether corporations can be said to have a moral character.', 'If any human being were to behave with the single-minded and ruthless greed of the company, we would consider them sociopathic.', 'Uber wanted to know as much as possible about the people who use its service, and those who don’t.', 'It has an arrangement with unroll.me, a company which offered a free service for unsubscribing from junk mail, to buy the contacts unroll.me customers had had with rival taxi companies.', 'Even if their email was notionally anonymised, this use of it was not something the users had bargained for.', 'Beyond that, it keeps track of the phones that have been used to summon its services even after the original owner has sold them, attempting this with Apple’s phones even thought it is forbidden by the company.', 'Uber has also tweaked its software so that regulatory agencies that the company regarded as hostile would, when they tried to hire a driver, be given false reports about the location of its cars.', 'Uber management booked and then cancelled rides with a rival taxi-hailing company which took their vehicles out of circulation.', 'Uber deny this was the intention.', 'The punishment for this behaviour was negligible.', 'Uber promised not to use this “greyball” software against law enforcement – one wonders what would happen to someone carrying a knife who promised never to stab a policeman with it.', 'Travis Kalanick of Uber got a personal dressing down from Tim Cook, who runs Apple, but the company did not prohibit the use of the app.', 'Too much money was at stake for that.', 'Millions of people around the world value the cheapness and convenience of Uber’s rides too much to care about the lack of drivers’ rights or pay.', 'Many of the users themselves are not much richer than the drivers.', 'The “sharing economy” encourages the insecure and exploited to exploit others equally insecure to the profit of a tiny clique of billionaires.', 'Silicon Valley’s culture seems hostile to humane and democratic values.', 'The outgoing CEO of Yahoo, Marissa Mayer, who is widely judged to have been a failure, is likely to get a $186m payout.', 'This may not be a cause for panic, any more than the previous hero worship should have been a cause for euphoria.', 'Yet there’s an urgent political task to tame these companies, to ensure they are punished when they break the law, that they pay their taxes fairly and that they behave responsibly.']\n",
            "[['The', 'taxi-hailing', 'company', 'Uber', 'brings', 'into', 'very', 'sharp', 'focus', 'the', 'question', 'of', 'whether', 'corporations', 'can', 'be', 'said', 'to', 'have', 'a', 'moral', 'character', '.'], ['If', 'any', 'human', 'being', 'were', 'to', 'behave', 'with', 'the', 'single-minded', 'and', 'ruthless', 'greed', 'of', 'the', 'company', ',', 'we', 'would', 'consider', 'them', 'sociopathic', '.'], ['Uber', 'wanted', 'to', 'know', 'as', 'much', 'as', 'possible', 'about', 'the', 'people', 'who', 'use', 'its', 'service', ',', 'and', 'those', 'who', 'don', '’', 't', '.'], ['It', 'has', 'an', 'arrangement', 'with', 'unroll.me', ',', 'a', 'company', 'which', 'offered', 'a', 'free', 'service', 'for', 'unsubscribing', 'from', 'junk', 'mail', ',', 'to', 'buy', 'the', 'contacts', 'unroll.me', 'customers', 'had', 'had', 'with', 'rival', 'taxi', 'companies', '.'], ['Even', 'if', 'their', 'email', 'was', 'notionally', 'anonymised', ',', 'this', 'use', 'of', 'it', 'was', 'not', 'something', 'the', 'users', 'had', 'bargained', 'for', '.'], ['Beyond', 'that', ',', 'it', 'keeps', 'track', 'of', 'the', 'phones', 'that', 'have', 'been', 'used', 'to', 'summon', 'its', 'services', 'even', 'after', 'the', 'original', 'owner', 'has', 'sold', 'them', ',', 'attempting', 'this', 'with', 'Apple', '’', 's', 'phones', 'even', 'thought', 'it', 'is', 'forbidden', 'by', 'the', 'company', '.'], ['Uber', 'has', 'also', 'tweaked', 'its', 'software', 'so', 'that', 'regulatory', 'agencies', 'that', 'the', 'company', 'regarded', 'as', 'hostile', 'would', ',', 'when', 'they', 'tried', 'to', 'hire', 'a', 'driver', ',', 'be', 'given', 'false', 'reports', 'about', 'the', 'location', 'of', 'its', 'cars', '.'], ['Uber', 'management', 'booked', 'and', 'then', 'cancelled', 'rides', 'with', 'a', 'rival', 'taxi-hailing', 'company', 'which', 'took', 'their', 'vehicles', 'out', 'of', 'circulation', '.'], ['Uber', 'deny', 'this', 'was', 'the', 'intention', '.'], ['The', 'punishment', 'for', 'this', 'behaviour', 'was', 'negligible', '.'], ['Uber', 'promised', 'not', 'to', 'use', 'this', '“', 'greyball', '”', 'software', 'against', 'law', 'enforcement', '–', 'one', 'wonders', 'what', 'would', 'happen', 'to', 'someone', 'carrying', 'a', 'knife', 'who', 'promised', 'never', 'to', 'stab', 'a', 'policeman', 'with', 'it', '.'], ['Travis', 'Kalanick', 'of', 'Uber', 'got', 'a', 'personal', 'dressing', 'down', 'from', 'Tim', 'Cook', ',', 'who', 'runs', 'Apple', ',', 'but', 'the', 'company', 'did', 'not', 'prohibit', 'the', 'use', 'of', 'the', 'app', '.'], ['Too', 'much', 'money', 'was', 'at', 'stake', 'for', 'that', '.'], ['Millions', 'of', 'people', 'around', 'the', 'world', 'value', 'the', 'cheapness', 'and', 'convenience', 'of', 'Uber', '’', 's', 'rides', 'too', 'much', 'to', 'care', 'about', 'the', 'lack', 'of', 'drivers', '’', 'rights', 'or', 'pay', '.'], ['Many', 'of', 'the', 'users', 'themselves', 'are', 'not', 'much', 'richer', 'than', 'the', 'drivers', '.'], ['The', '“', 'sharing', 'economy', '”', 'encourages', 'the', 'insecure', 'and', 'exploited', 'to', 'exploit', 'others', 'equally', 'insecure', 'to', 'the', 'profit', 'of', 'a', 'tiny', 'clique', 'of', 'billionaires', '.'], ['Silicon', 'Valley', '’', 's', 'culture', 'seems', 'hostile', 'to', 'humane', 'and', 'democratic', 'values', '.'], ['The', 'outgoing', 'CEO', 'of', 'Yahoo', ',', 'Marissa', 'Mayer', ',', 'who', 'is', 'widely', 'judged', 'to', 'have', 'been', 'a', 'failure', ',', 'is', 'likely', 'to', 'get', 'a', '$', '186m', 'payout', '.'], ['This', 'may', 'not', 'be', 'a', 'cause', 'for', 'panic', ',', 'any', 'more', 'than', 'the', 'previous', 'hero', 'worship', 'should', 'have', 'been', 'a', 'cause', 'for', 'euphoria', '.'], ['Yet', 'there', '’', 's', 'an', 'urgent', 'political', 'task', 'to', 'tame', 'these', 'companies', ',', 'to', 'ensure', 'they', 'are', 'punished', 'when', 'they', 'break', 'the', 'law', ',', 'that', 'they', 'pay', 'their', 'taxes', 'fairly', 'and', 'that', 'they', 'behave', 'responsibly', '.']]\n",
            "[[('The', 'DT'), ('taxi-hailing', 'JJ'), ('company', 'NN'), ('Uber', 'NNP'), ('brings', 'VBZ'), ('into', 'IN'), ('very', 'RB'), ('sharp', 'JJ'), ('focus', 'VB'), ('the', 'DT'), ('question', 'NN'), ('of', 'IN'), ('whether', 'IN'), ('corporations', 'NNS'), ('can', 'MD'), ('be', 'VB'), ('said', 'VBD'), ('to', 'TO'), ('have', 'VB'), ('a', 'DT'), ('moral', 'JJ'), ('character', 'NN'), ('.', '.')], [('If', 'IN'), ('any', 'DT'), ('human', 'JJ'), ('being', 'VBG'), ('were', 'VBD'), ('to', 'TO'), ('behave', 'VB'), ('with', 'IN'), ('the', 'DT'), ('single-minded', 'JJ'), ('and', 'CC'), ('ruthless', 'JJ'), ('greed', 'NN'), ('of', 'IN'), ('the', 'DT'), ('company', 'NN'), (',', ','), ('we', 'PRP'), ('would', 'MD'), ('consider', 'VB'), ('them', 'PRP'), ('sociopathic', 'JJ'), ('.', '.')], [('Uber', 'NNP'), ('wanted', 'VBD'), ('to', 'TO'), ('know', 'VB'), ('as', 'RB'), ('much', 'JJ'), ('as', 'IN'), ('possible', 'JJ'), ('about', 'IN'), ('the', 'DT'), ('people', 'NNS'), ('who', 'WP'), ('use', 'VBP'), ('its', 'PRP$'), ('service', 'NN'), (',', ','), ('and', 'CC'), ('those', 'DT'), ('who', 'WP'), ('don', 'VBP'), ('’', 'JJ'), ('t', 'NN'), ('.', '.')], [('It', 'PRP'), ('has', 'VBZ'), ('an', 'DT'), ('arrangement', 'NN'), ('with', 'IN'), ('unroll.me', 'JJ'), (',', ','), ('a', 'DT'), ('company', 'NN'), ('which', 'WDT'), ('offered', 'VBD'), ('a', 'DT'), ('free', 'JJ'), ('service', 'NN'), ('for', 'IN'), ('unsubscribing', 'VBG'), ('from', 'IN'), ('junk', 'NN'), ('mail', 'NN'), (',', ','), ('to', 'TO'), ('buy', 'VB'), ('the', 'DT'), ('contacts', 'NNS'), ('unroll.me', 'JJ'), ('customers', 'NNS'), ('had', 'VBD'), ('had', 'VBN'), ('with', 'IN'), ('rival', 'JJ'), ('taxi', 'NN'), ('companies', 'NNS'), ('.', '.')], [('Even', 'RB'), ('if', 'IN'), ('their', 'PRP$'), ('email', 'NN'), ('was', 'VBD'), ('notionally', 'RB'), ('anonymised', 'VBN'), (',', ','), ('this', 'DT'), ('use', 'NN'), ('of', 'IN'), ('it', 'PRP'), ('was', 'VBD'), ('not', 'RB'), ('something', 'NN'), ('the', 'DT'), ('users', 'NNS'), ('had', 'VBD'), ('bargained', 'VBN'), ('for', 'IN'), ('.', '.')], [('Beyond', 'NN'), ('that', 'IN'), (',', ','), ('it', 'PRP'), ('keeps', 'VBZ'), ('track', 'NN'), ('of', 'IN'), ('the', 'DT'), ('phones', 'NNS'), ('that', 'WDT'), ('have', 'VBP'), ('been', 'VBN'), ('used', 'VBN'), ('to', 'TO'), ('summon', 'VB'), ('its', 'PRP$'), ('services', 'NNS'), ('even', 'RB'), ('after', 'IN'), ('the', 'DT'), ('original', 'JJ'), ('owner', 'NN'), ('has', 'VBZ'), ('sold', 'VBN'), ('them', 'PRP'), (',', ','), ('attempting', 'VBG'), ('this', 'DT'), ('with', 'IN'), ('Apple', 'NNP'), ('’', 'NNP'), ('s', 'VBP'), ('phones', 'NNS'), ('even', 'RB'), ('thought', 'VBD'), ('it', 'PRP'), ('is', 'VBZ'), ('forbidden', 'VBN'), ('by', 'IN'), ('the', 'DT'), ('company', 'NN'), ('.', '.')], [('Uber', 'NNP'), ('has', 'VBZ'), ('also', 'RB'), ('tweaked', 'VBN'), ('its', 'PRP$'), ('software', 'NN'), ('so', 'IN'), ('that', 'DT'), ('regulatory', 'JJ'), ('agencies', 'NNS'), ('that', 'IN'), ('the', 'DT'), ('company', 'NN'), ('regarded', 'VBD'), ('as', 'IN'), ('hostile', 'NN'), ('would', 'MD'), (',', ','), ('when', 'WRB'), ('they', 'PRP'), ('tried', 'VBD'), ('to', 'TO'), ('hire', 'VB'), ('a', 'DT'), ('driver', 'NN'), (',', ','), ('be', 'VB'), ('given', 'VBN'), ('false', 'JJ'), ('reports', 'NNS'), ('about', 'IN'), ('the', 'DT'), ('location', 'NN'), ('of', 'IN'), ('its', 'PRP$'), ('cars', 'NNS'), ('.', '.')], [('Uber', 'NNP'), ('management', 'NN'), ('booked', 'VBD'), ('and', 'CC'), ('then', 'RB'), ('cancelled', 'VBD'), ('rides', 'NNS'), ('with', 'IN'), ('a', 'DT'), ('rival', 'JJ'), ('taxi-hailing', 'JJ'), ('company', 'NN'), ('which', 'WDT'), ('took', 'VBD'), ('their', 'PRP$'), ('vehicles', 'NNS'), ('out', 'IN'), ('of', 'IN'), ('circulation', 'NN'), ('.', '.')], [('Uber', 'NNP'), ('deny', 'NN'), ('this', 'DT'), ('was', 'VBD'), ('the', 'DT'), ('intention', 'NN'), ('.', '.')], [('The', 'DT'), ('punishment', 'NN'), ('for', 'IN'), ('this', 'DT'), ('behaviour', 'NN'), ('was', 'VBD'), ('negligible', 'JJ'), ('.', '.')], [('Uber', 'NNP'), ('promised', 'VBD'), ('not', 'RB'), ('to', 'TO'), ('use', 'VB'), ('this', 'DT'), ('“', 'NN'), ('greyball', 'NN'), ('”', 'NNP'), ('software', 'NN'), ('against', 'IN'), ('law', 'NN'), ('enforcement', 'NN'), ('–', 'NNP'), ('one', 'NN'), ('wonders', 'VBZ'), ('what', 'WDT'), ('would', 'MD'), ('happen', 'VB'), ('to', 'TO'), ('someone', 'NN'), ('carrying', 'VBG'), ('a', 'DT'), ('knife', 'NN'), ('who', 'WP'), ('promised', 'VBD'), ('never', 'RB'), ('to', 'TO'), ('stab', 'VB'), ('a', 'DT'), ('policeman', 'NN'), ('with', 'IN'), ('it', 'PRP'), ('.', '.')], [('Travis', 'NNP'), ('Kalanick', 'NNP'), ('of', 'IN'), ('Uber', 'NNP'), ('got', 'VBD'), ('a', 'DT'), ('personal', 'JJ'), ('dressing', 'VBG'), ('down', 'RP'), ('from', 'IN'), ('Tim', 'NNP'), ('Cook', 'NNP'), (',', ','), ('who', 'WP'), ('runs', 'VBZ'), ('Apple', 'NNP'), (',', ','), ('but', 'CC'), ('the', 'DT'), ('company', 'NN'), ('did', 'VBD'), ('not', 'RB'), ('prohibit', 'VB'), ('the', 'DT'), ('use', 'NN'), ('of', 'IN'), ('the', 'DT'), ('app', 'NN'), ('.', '.')], [('Too', 'RB'), ('much', 'JJ'), ('money', 'NN'), ('was', 'VBD'), ('at', 'IN'), ('stake', 'NN'), ('for', 'IN'), ('that', 'DT'), ('.', '.')], [('Millions', 'NNS'), ('of', 'IN'), ('people', 'NNS'), ('around', 'IN'), ('the', 'DT'), ('world', 'NN'), ('value', 'NN'), ('the', 'DT'), ('cheapness', 'NN'), ('and', 'CC'), ('convenience', 'NN'), ('of', 'IN'), ('Uber', 'NNP'), ('’', 'NNP'), ('s', 'VBD'), ('rides', 'NNS'), ('too', 'RB'), ('much', 'RB'), ('to', 'TO'), ('care', 'VB'), ('about', 'IN'), ('the', 'DT'), ('lack', 'NN'), ('of', 'IN'), ('drivers', 'NNS'), ('’', 'NNP'), ('rights', 'NNS'), ('or', 'CC'), ('pay', 'NN'), ('.', '.')], [('Many', 'JJ'), ('of', 'IN'), ('the', 'DT'), ('users', 'NNS'), ('themselves', 'PRP'), ('are', 'VBP'), ('not', 'RB'), ('much', 'RB'), ('richer', 'JJR'), ('than', 'IN'), ('the', 'DT'), ('drivers', 'NNS'), ('.', '.')], [('The', 'DT'), ('“', 'JJ'), ('sharing', 'VBG'), ('economy', 'NN'), ('”', 'JJ'), ('encourages', 'VBZ'), ('the', 'DT'), ('insecure', 'NN'), ('and', 'CC'), ('exploited', 'VBD'), ('to', 'TO'), ('exploit', 'VB'), ('others', 'NNS'), ('equally', 'RB'), ('insecure', 'VBP'), ('to', 'TO'), ('the', 'DT'), ('profit', 'NN'), ('of', 'IN'), ('a', 'DT'), ('tiny', 'JJ'), ('clique', 'NN'), ('of', 'IN'), ('billionaires', 'NNS'), ('.', '.')], [('Silicon', 'NNP'), ('Valley', 'NNP'), ('’', 'NNP'), ('s', 'JJ'), ('culture', 'NN'), ('seems', 'VBZ'), ('hostile', 'JJ'), ('to', 'TO'), ('humane', 'NN'), ('and', 'CC'), ('democratic', 'JJ'), ('values', 'NNS'), ('.', '.')], [('The', 'DT'), ('outgoing', 'VBG'), ('CEO', 'NNP'), ('of', 'IN'), ('Yahoo', 'NNP'), (',', ','), ('Marissa', 'NNP'), ('Mayer', 'NNP'), (',', ','), ('who', 'WP'), ('is', 'VBZ'), ('widely', 'RB'), ('judged', 'VBN'), ('to', 'TO'), ('have', 'VB'), ('been', 'VBN'), ('a', 'DT'), ('failure', 'NN'), (',', ','), ('is', 'VBZ'), ('likely', 'JJ'), ('to', 'TO'), ('get', 'VB'), ('a', 'DT'), ('$', '$'), ('186m', 'CD'), ('payout', 'NN'), ('.', '.')], [('This', 'DT'), ('may', 'MD'), ('not', 'RB'), ('be', 'VB'), ('a', 'DT'), ('cause', 'NN'), ('for', 'IN'), ('panic', 'NN'), (',', ','), ('any', 'DT'), ('more', 'JJR'), ('than', 'IN'), ('the', 'DT'), ('previous', 'JJ'), ('hero', 'NN'), ('worship', 'NN'), ('should', 'MD'), ('have', 'VB'), ('been', 'VBN'), ('a', 'DT'), ('cause', 'NN'), ('for', 'IN'), ('euphoria', 'NN'), ('.', '.')], [('Yet', 'RB'), ('there', 'EX'), ('’', 'NNP'), ('s', 'VBD'), ('an', 'DT'), ('urgent', 'JJ'), ('political', 'JJ'), ('task', 'NN'), ('to', 'TO'), ('tame', 'VB'), ('these', 'DT'), ('companies', 'NNS'), (',', ','), ('to', 'TO'), ('ensure', 'VB'), ('they', 'PRP'), ('are', 'VBP'), ('punished', 'VBN'), ('when', 'WRB'), ('they', 'PRP'), ('break', 'VBP'), ('the', 'DT'), ('law', 'NN'), (',', ','), ('that', 'IN'), ('they', 'PRP'), ('pay', 'VBP'), ('their', 'PRP$'), ('taxes', 'NNS'), ('fairly', 'RB'), ('and', 'CC'), ('that', 'IN'), ('they', 'PRP'), ('behave', 'VBP'), ('responsibly', 'RB'), ('.', '.')]]\n",
            "(NE Uber/NNP)\n",
            "(NE Beyond/NN)\n",
            "(NE Apple/NNP)\n",
            "(NE Uber/NNP)\n",
            "(NE Uber/NNP)\n",
            "(NE Travis/NNP Kalanick/NNP)\n",
            "(NE Tim/NNP Cook/NNP)\n",
            "(NE Apple/NNP)\n",
            "(NE Silicon/NNP Valley/NNP)\n",
            "(NE CEO/NNP)\n",
            "(NE Yahoo/NNP)\n",
            "(NE Marissa/NNP Mayer/NNP)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "smvg_OiQokvM",
        "outputId": "c4136c48-24c5-415a-8f11-d1df863db94d"
      },
      "source": [
        "#Create the defaultdict: ner_categories\n",
        "from collections import defaultdict\n",
        "ner_categories = defaultdict(int)\n",
        "\n",
        "# Create the nested for loop\n",
        "for sent in chunked_sentences:\n",
        "    for chunk in sent:\n",
        "        if hasattr(chunk, 'label'):\n",
        "            ner_categories[chunk.label()] += 1\n",
        "            \n",
        "# Create a list from the dictionary keys for the chart labels: labels\n",
        "labels = list(ner_categories.keys())\n",
        "\n",
        "# Create a list of the values: values\n",
        "values = [ner_categories.get(v) for v in labels]\n",
        "\n",
        "# Create the pie chart\n",
        "plt.pie(values, labels=labels, autopct='%1.1f%%', startangle=140)\n",
        "\n",
        "# Display the chart\n",
        "plt.show()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAACtklEQVR4nO3TMQEAIAzAMMC/52GAnx6Jgj7dM7OAnvM7AHgzJ0SZE6LMCVHmhChzQpQ5IcqcEGVOiDInRJkToswJUeaEKHNClDkhypwQZU6IMidEmROizAlR5oQoc0KUOSHKnBBlTogyJ0SZE6LMCVHmhChzQpQ5IcqcEGVOiDInRJkToswJUeaEKHNClDkhypwQZU6IMidEmROizAlR5oQoc0KUOSHKnBBlTogyJ0SZE6LMCVHmhChzQpQ5IcqcEGVOiDInRJkToswJUeaEKHNClDkhypwQZU6IMidEmROizAlR5oQoc0KUOSHKnBBlTogyJ0SZE6LMCVHmhChzQpQ5IcqcEGVOiDInRJkToswJUeaEKHNClDkhypwQZU6IMidEmROizAlR5oQoc0KUOSHKnBBlTogyJ0SZE6LMCVHmhChzQpQ5IcqcEGVOiDInRJkToswJUeaEKHNClDkhypwQZU6IMidEmROizAlR5oQoc0KUOSHKnBBlTogyJ0SZE6LMCVHmhChzQpQ5IcqcEGVOiDInRJkToswJUeaEKHNClDkhypwQZU6IMidEmROizAlR5oQoc0KUOSHKnBBlTogyJ0SZE6LMCVHmhChzQpQ5IcqcEGVOiDInRJkToswJUeaEKHNClDkhypwQZU6IMidEmROizAlR5oQoc0KUOSHKnBBlTogyJ0SZE6LMCVHmhChzQpQ5IcqcEGVOiDInRJkToswJUeaEKHNClDkhypwQZU6IMidEmROizAlR5oQoc0KUOSHKnBBlTogyJ0SZE6LMCVHmhChzQpQ5IcqcEGVOiDInRJkToswJUeaEKHNClDkhypwQZU6IMidEmROizAlR5oQoc0KUOSHKnBBlTogyJ0SZE6LMCVHmhChzQpQ5IcqcEGVOiDInRJkToswJUeaEKHNC1AVcegTL+uSnUAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSZYwfgGpQbg",
        "outputId": "618fe4b3-5f51-461e-99bc-1f474be8aedb"
      },
      "source": [
        "print(ner_categories)\n",
        "print(labels)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defaultdict(<class 'int'>, {})\n",
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2N8h08KdTGt"
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en')"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "he0GNh54jVxA",
        "outputId": "dec2df81-2420-4344-f5f1-5d60208896e7"
      },
      "source": [
        "nlp.entity"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.pipeline.pipes.EntityRecognizer at 0x7f76ef44bb40>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4NcWra1jgNv",
        "outputId": "36c78362-7e9d-43f4-bd9c-48919fc5d794"
      },
      "source": [
        "doc = nlp(\"\"\"Berlin is the capital of Germany and the residence of Chancellor Angela Merkel.\"\"\")\n",
        "doc.ents"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Berlin, Germany, Angela Merkel)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlJ5-qnljwvR",
        "outputId": "705973fa-dbf5-4cc3-b65e-6039cc612676"
      },
      "source": [
        "print(doc.ents[0], doc.ents[0].label_)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Berlin GPE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dilHsoQpxjNH",
        "outputId": "56e29b56-4877-42bf-8ce0-89cbf5285b65"
      },
      "source": [
        "# !pip install pyicu\n",
        "# !pip install pycld2\n",
        "# !pip install morfessor\n",
        "!polyglot download ner2.fr\n",
        "!polyglot download embeddings2.fr"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[polyglot_data] Downloading package ner2.fr to /root/polyglot_data...\n",
            "[polyglot_data]   Package ner2.fr is already up-to-date!\n",
            "[polyglot_data] Downloading package embeddings2.fr to\n",
            "[polyglot_data]     /root/polyglot_data...\n",
            "[polyglot_data]   Package embeddings2.fr is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5axZv1HsU0F",
        "outputId": "ac6ac487-a4cb-4de0-8c37-835f20951b38"
      },
      "source": [
        "import spacy\n",
        "\n",
        "# Instantiate the English model: nlp\n",
        "nlp = spacy.load('en', tagger=False, parser=False, matcher=False)\n",
        "\n",
        "# Create a new document: doc\n",
        "doc = nlp(article)\n",
        "\n",
        "# Print all of the found entities and their labels\n",
        "for entity in doc.ents:\n",
        "    print(entity.label_, entity.text)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ORG Uber\n",
            "PERSON Uber\n",
            "ORG unroll.me\n",
            "ORG Apple\n",
            "PERSON Travis Kalanick\n",
            "PERSON Uber\n",
            "PERSON Tim Cook\n",
            "ORG Apple\n",
            "CARDINAL Millions\n",
            "PERSON Uber\n",
            "LOC Silicon Valley\n",
            "ORG Yahoo\n",
            "PERSON Marissa Mayer\n",
            "MONEY $186m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l753Wp84sUnH"
      },
      "source": [
        "article = 'édition abonné Dans une tribune au « Monde », l’universitaire Charles Cuvelliez estime que le fantasme d’un remplacement de l’homme par l’algorithme et le robot repose sur un malentendu. Le Monde | 10.05.2017 à 06h44 • Mis à jour le 10.05.2017 à 09h47 | Par Charles Cuvelliez (Professeur à l’Ecole polytechnique de l université libre de Bruxelles) TRIBUNE. L’usage morbide, par certains, de Facebook Live a amené son fondateur à annoncer précipitamment le recrutement de 3 000 modérateurs supplémentaires. Il est vrai que l’intelligence artificielle (IA) est bien en peine de reconnaître des contenus violents, surtout diffusés en direct. Le quotidien affreux de ces modérateurs, contraints de visionner des horreurs à longueur de journée, mériterait pourtant qu’on les remplace vite par des machines ! L’IA ne peut pas tout, mais là où elle peut beaucoup, on la maudit, accusée de détruire nos emplois, de remplacer la convivialité humaine. Ce débat repose sur un malentendu. Il vient d’une définition de l’IA qui n’a, dans la réalité, jamais pu être mise en pratique : en 1955, elle était vue comme la création de programmes informatiques qui, quoi qu’on leur confie, le feraient un jour mieux que les humains. On pensait que toute caractéristique de l’intelligence humaine pourrait un jour être si précisément décrite qu’il suffirait d’une machine pour la simuler. Ce n’est pas vrai. Angoisses infondées Comme le dit un récent Livre blanc sur la question (Pourquoi il ne faut pas avoir peur de l’Intelligence arti­ficielle, Julien Maldonato, Deloitte, mars 2017), rien ne pourra remplacer un humain dans sa globalité. L’IA, c’est de l’apprentissage automatique doté d’un processus d’ajustement de modèles statistiques à des masses de données, explique l’auteur. Il s’agit d’un apprentissage sur des paramètres pour lesquels une vision humaine n’explique pas pourquoi ils marchent si bien dans un contexte donné. C’est aussi ce que dit le rapport de l’Office parlementaire d’évaluation des choix scientifiques et technologiques (« Pour une intelligence artificielle maîtrisée, utile et démystifiée », 29 mars 2017), pour qui ce côté « boîte noire » explique des angoisses infondées. Ethiquement, se fonder sur l’IA pour des tâches critiques sans bien comprendre le comment...'"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OLXsPrCzaaf",
        "outputId": "702a2fec-9bb1-4dbb-db4b-5b66f9692a41"
      },
      "source": [
        "from polyglot.text import Text\n",
        "txt = Text(article)\n",
        "\n",
        "# Print each of the entities found\n",
        "for ent in txt.entities:\n",
        "    print(ent)\n",
        "    \n",
        "# Print the type of ent\n",
        "print(type(ent))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Charles', 'Cuvelliez']\n",
            "['Charles', 'Cuvelliez']\n",
            "['polytechnique']\n",
            "['libre', 'de', 'Bruxelles']\n",
            "['l’IA']\n",
            "['Julien', 'Maldonato']\n",
            "['Deloitte']\n",
            "['Ethiquement']\n",
            "['l’IA']\n",
            "['.']\n",
            "<class 'polyglot.text.Chunk'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkDgts_czhmJ"
      },
      "source": [
        "text = 'किसी एक भाव या विचार को व्यक्त करने के लिए लिखे गये सम्बद्ध और लघु वाक्य-समूह को अनुच्छेद-लेखन कहते हैं। दूसरे शब्दों में - किसी घटना, दृश्य अथवा विषय को संक्षिप्त (कम शब्दों में) किन्तु सारगर्भित (अर्थपूर्ण) ढंग से जिस लेखन-शैली में प्रस्तुत किया जाता है, उसे अनुच्छेद-लेखन कहते हैं। अनुच्छेद शब्द अंग्रेजी भाषा के शब्द का हिंदी पर्याय है। अनुच्छेद निबंध का संक्षिप्त रूप होता है। इसमें किसी विषय के किसी एक पक्ष पर 80 से 100 शब्दों में अपने विचार व्यक्त किए जाते हैं। अनुच्छेद अपने-आप में स्वतन्त्र और पूर्ण होते हैं। अनुच्छेद का मुख्य विचार या भाव की कुंजी या तो आरम्भ में रहती है या अन्त में। एक अच्छे अनुच्छेद-लेखन में मुख्य विचार अन्त में दिया जाता है।'\n"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYs1crVrtN49",
        "outputId": "5e0eb73d-e545-40f1-b8d4-b6bb0542e642"
      },
      "source": [
        "ptxt = Text(text)\n",
        "!polyglot download ner2.en\n",
        "ptxt.entities"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[polyglot_data] Downloading package ner2.en to /root/polyglot_data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    }
  ]
}